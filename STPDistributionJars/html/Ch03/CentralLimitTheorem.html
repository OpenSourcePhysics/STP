<!DOCTYPE html>



<html>

<head>
  <title>CentralLimitTheorem</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta charset="utf-8" />

  </head>

<body>

  <h1 id="myTitle" style="position:fixed;">Program CentralLimitTheorem</h1>


  <div style="position:absolute;left:30px;top:500px;">

  


<p>The central limit theorem explains why Gaussian distributions are so common, and in particular is essential for
thermodynamics. Any quantity which is the sum of 
individual terms whose values are described by almost any probability distribution, will be described by the Gaussian distribution. 
The key requirement is that the distribution describing the individual values must have a finite second moment.     </p>

<p>Program <code>CentralLimitTheorem</code> lets you test the central limit theorem for three  distributions, and explore the distribution as a function of the number of terms N in the sum.    </p>

<h2>Problem: Central limit theorem</h2>

<p>Use Program <code>CentralLimitTheorem</code> to test the applicability of the central
limit theorem. 

<ol type ="a">

<li> Assume that the variable
s is uniformly distributed between 0 and 1. Calculate analytically the
mean and standard deviation of s and compare your numerical
results from the program with your analytical calculation.</li>

<li> Use the default value of N = 12, the number of terms in the sum S = &Sigma;<sub>i=1</sub> s<sub>i</sub>, and 
describe the qualitative form of p(S) that is computed and plotted by the program; p(S)&Delta; S is 
the probability that the sum S is between S and S + &Delta; S. Does the qualitative form of p(S) 
change as the number of measurements (trials) of S is increased for a given value of N?</li>

<li> What is the approximate width of p(S) for N = 12? Describe the changes, if any, of the width of p(S) as N is increased. Increase N by at least a factor of four.
Do
your results depend strongly on the number of
measurements?</li>

<li> To determine the generality of your results, 
consider the probability density f(s) = e<sup>-s</sup> for s &ge; 0 and answer the 
same questions as in parts (a)--(c).</li>

<li> Consider the  Lorentz distribution
f(s) = (1/&pi;)(1/(s<sup>2</sup> + 1)), 
where -&infin; &le; s &le; &infin;. What is the mean value and variance of s? 
Is the form of p(S) consistent with the results that you found 
in parts (b)--(d)?</li>

<li> *Each value of S can be considered to be a measurement. The sample variance &sigma;<sub>S</sub><sup>2</sup> is 
a measure of the square of the differences of the result of each measurement and is given by<br>
&sigma;<sub>S</sub><sup>2</sup> = [1/(N-1)]&sum;<sub>j=1</sub> (S<sub>j</sub> - &lt;S&gt;)<sup>2</sup>.
</br>
The reason for the factor of N-1 rather than N in the definition of  &sigma;<sub>S</sub><sup>2</sup> is that to 
compute it, we need to use the N values of s to compute the mean of S. Thus, loosely speaking, we 
have only N-1 independent values of s remaining to calculate &sigma;<sub>S</sub><sup>2</sup>. 
Show that if N &#8811; 1, then  
&sigma;<sub>S</sub><sup>2</sup> = &lt;S<sup>2</sup>&gt; - &lt;S&gt;<sup>2</sup>.</li>

<li> <sup>*</sup>The quantity &sigma;<sub>S</sub> 
is known as the  <i>standard deviation of the means</i>. 
That is, &sigma;<sub>S</sub> is a measure of how much variation we expect to find if we make repeated 
measurements of S. How does the value of &sigma;<sub>S</sub> compare to your estimated width of the 
probability density p(S)? </li>
</ol>

   <h2>Resources</h2>
  <ul>

  
    
    <li>Problem 3.51 in <i>Statistical and Thermal Physics: With Computer Applications</i>, 2nd ed., 
    Harvey Gould and Jan Tobochnik, Princeton University Press (2021).</li>

 
</ul>

 
  <p class="small">Updated 26 August 2020.</p>
</div>

</body>

</html>